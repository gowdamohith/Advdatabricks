{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_c0</th><th>_c1</th><th>_c2</th></tr></thead><tbody><tr><td>ID</td><td>Name</td><td>Age</td></tr><tr><td>1</td><td>Rohit</td><td>24</td></tr><tr><td>2</td><td>Virat</td><td>23</td></tr><tr><td>3</td><td>Shreyas</td><td>34</td></tr><tr><td>4</td><td>Axar</td><td>20</td></tr><tr><td>5</td><td>Rahul</td><td>30</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ID",
         "Name",
         "Age"
        ],
        [
         "1",
         "Rohit",
         "24"
        ],
        [
         "2",
         "Virat",
         "23"
        ],
        [
         "3",
         "Shreyas",
         "34"
        ],
        [
         "4",
         "Axar",
         "20"
        ],
        [
         "5",
         "Rahul",
         "30"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "_c0",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_c1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_c2",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/student-3.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3503165e-ccdc-4fbb-aab8-5e1b3748132a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n| ID|   Name|Age|\n+---+-------+---+\n|  1|  Rohit| 24|\n|  2|  Virat| 23|\n|  3|Shreyas| 34|\n|  4|   Axar| 20|\n|  5|  Rahul| 30|\n+---+-------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Define file location (Ensure this is an absolute path)\n",
    "file_location = \"/FileStore/tables/student-3.csv\"  # Change this to the correct path\n",
    "# Define CSV options\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"true\"  # Automatically infer schema\n",
    "first_row_is_header = \"true\"  # First row contains column names\n",
    "delimiter = \",\"  # Column separator\n",
    "# Read CSV into DataFrame\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "# Show DataFrame content\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf0160f9-491f-43d3-9a7e-7bdc28effaa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d8da6c-4bbc-452f-85e5-96302b5b6450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/employee.csv</td><td>employee.csv</td><td>61</td><td>1742367610000</td></tr><tr><td>dbfs:/FileStore/tables/student-1.csv</td><td>student-1.csv</td><td>74</td><td>1742365972000</td></tr><tr><td>dbfs:/FileStore/tables/student-2.csv</td><td>student-2.csv</td><td>74</td><td>1742366386000</td></tr><tr><td>dbfs:/FileStore/tables/student-3.csv</td><td>student-3.csv</td><td>74</td><td>1742373717000</td></tr><tr><td>dbfs:/FileStore/tables/student.csv</td><td>student.csv</td><td>74</td><td>1742365861000</td></tr><tr><td>dbfs:/FileStore/tables/student_csv.xlsx</td><td>student_csv.xlsx</td><td>8518</td><td>1742365410000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/employee.csv",
         "employee.csv",
         61,
         1742367610000
        ],
        [
         "dbfs:/FileStore/tables/student-1.csv",
         "student-1.csv",
         74,
         1742365972000
        ],
        [
         "dbfs:/FileStore/tables/student-2.csv",
         "student-2.csv",
         74,
         1742366386000
        ],
        [
         "dbfs:/FileStore/tables/student-3.csv",
         "student-3.csv",
         74,
         1742373717000
        ],
        [
         "dbfs:/FileStore/tables/student.csv",
         "student.csv",
         74,
         1742365861000
        ],
        [
         "dbfs:/FileStore/tables/student_csv.xlsx",
         "student_csv.xlsx",
         8518,
         1742365410000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "707a1abb-0ed3-4662-9f0a-1e7cbed36f7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a view or table\n",
    "temp_table_name = \"Restaurant_customer_data_csv\"\n",
    "df.createOrReplaceTempView(temp_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6179f28-c2f6-423b-824a-0a1234c23516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 122810 bytes.\n:open_file_folder: File /FileStore/tables/streaming_data_1742376128.csv with 5000 rows added!\nWrote 123920 bytes.\n:open_file_folder: File /FileStore/tables/streaming_data_1742376130.csv with 5000 rows added!\nWrote 123920 bytes.\n:open_file_folder: File /FileStore/tables/streaming_data_1742376132.csv with 5000 rows added!\n:rocket: Streaming spike triggered! Check console for new data.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Function to create a CSV file with streaming data\n",
    "def create_streaming_file(file_num, rows=10000):\n",
    "    csv_data = \"EMPLOYEE_ID,FIRST_NAME,SALARY\\n\"  # CSV header\n",
    "    for i in range(rows):\n",
    "        csv_data += f\"{file_num * 1000 + i},Employee_{i},{50000 + (i % 10000)}\\n\"\n",
    "    file_path = f\"/FileStore/tables/streaming_data_{int(time.time())}.csv\"\n",
    "    dbutils.fs.put(file_path, csv_data, True)\n",
    "    print(f\":open_file_folder: File {file_path} with {rows} rows added!\")\n",
    "# Generate multiple files to create a data spike\n",
    "for i in range(3):  # 3 large files\n",
    "    create_streaming_file(i, rows=5000)  # Each file has 5000 rows\n",
    "    time.sleep(2)  # Small delay between file creations\n",
    "print(\":rocket: Streaming spike triggered! Check console for new data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b154478-c0d4-471f-9424-9d4d860581bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "spark = SparkSession.builder.appName(\"StreamingDemo\").getOrCreate()\n",
    "# Define the schema explicitly\n",
    "schema = StructType([\n",
    "    StructField(\"EMPLOYEE_ID\", StringType(), True),\n",
    "    StructField(\"FIRST_NAME\", StringType(), True),\n",
    "    StructField(\"SALARY\", IntegerType(), True)\n",
    "])\n",
    "# Read streaming data from a folder\n",
    "df = spark.readStream.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema)  \\\n",
    "    .load(\"/FileStore/tables/\")\n",
    "# Apply a transformation\n",
    "df_transformed = df.select(\"EMPLOYEE_ID\", \"FIRST_NAME\", \"SALARY\")\n",
    "# Write the output to console with a trigger interval of 5 seconds\n",
    "query = df_transformed.writeStream.format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a6c9f3b-bee0-4ef9-91e4-017f45df7158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query.stop()  # Stop the existing stream\n",
    "# Restart the streaming query\n",
    "query = df_transformed.writeStream.format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63eb111b-63d1-4897-9a57-d8062f56483b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/employee.csv</td><td>employee.csv</td><td>61</td><td>1742367610000</td></tr><tr><td>dbfs:/FileStore/tables/streaming_data.csv</td><td>streaming_data.csv</td><td>64</td><td>1742376194000</td></tr><tr><td>dbfs:/FileStore/tables/streaming_data_1742376001.csv</td><td>streaming_data_1742376001.csv</td><td>122810</td><td>1742376002000</td></tr><tr><td>dbfs:/FileStore/tables/streaming_data_1742376003.csv</td><td>streaming_data_1742376003.csv</td><td>123920</td><td>1742376004000</td></tr><tr><td>dbfs:/FileStore/tables/streaming_data_1742376005.csv</td><td>streaming_data_1742376005.csv</td><td>123920</td><td>1742376006000</td></tr><tr><td>dbfs:/FileStore/tables/streaming_data_1742376128.csv</td><td>streaming_data_1742376128.csv</td><td>122810</td><td>1742376129000</td></tr><tr><td>dbfs:/FileStore/tables/streaming_data_1742376130.csv</td><td>streaming_data_1742376130.csv</td><td>123920</td><td>1742376131000</td></tr><tr><td>dbfs:/FileStore/tables/streaming_data_1742376132.csv</td><td>streaming_data_1742376132.csv</td><td>123920</td><td>1742376133000</td></tr><tr><td>dbfs:/FileStore/tables/student-1.csv</td><td>student-1.csv</td><td>74</td><td>1742365972000</td></tr><tr><td>dbfs:/FileStore/tables/student-2.csv</td><td>student-2.csv</td><td>74</td><td>1742366386000</td></tr><tr><td>dbfs:/FileStore/tables/student-3.csv</td><td>student-3.csv</td><td>74</td><td>1742373717000</td></tr><tr><td>dbfs:/FileStore/tables/student.csv</td><td>student.csv</td><td>74</td><td>1742365861000</td></tr><tr><td>dbfs:/FileStore/tables/student_csv.xlsx</td><td>student_csv.xlsx</td><td>8518</td><td>1742365410000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/employee.csv",
         "employee.csv",
         61,
         1742367610000
        ],
        [
         "dbfs:/FileStore/tables/streaming_data.csv",
         "streaming_data.csv",
         64,
         1742376194000
        ],
        [
         "dbfs:/FileStore/tables/streaming_data_1742376001.csv",
         "streaming_data_1742376001.csv",
         122810,
         1742376002000
        ],
        [
         "dbfs:/FileStore/tables/streaming_data_1742376003.csv",
         "streaming_data_1742376003.csv",
         123920,
         1742376004000
        ],
        [
         "dbfs:/FileStore/tables/streaming_data_1742376005.csv",
         "streaming_data_1742376005.csv",
         123920,
         1742376006000
        ],
        [
         "dbfs:/FileStore/tables/streaming_data_1742376128.csv",
         "streaming_data_1742376128.csv",
         122810,
         1742376129000
        ],
        [
         "dbfs:/FileStore/tables/streaming_data_1742376130.csv",
         "streaming_data_1742376130.csv",
         123920,
         1742376131000
        ],
        [
         "dbfs:/FileStore/tables/streaming_data_1742376132.csv",
         "streaming_data_1742376132.csv",
         123920,
         1742376133000
        ],
        [
         "dbfs:/FileStore/tables/student-1.csv",
         "student-1.csv",
         74,
         1742365972000
        ],
        [
         "dbfs:/FileStore/tables/student-2.csv",
         "student-2.csv",
         74,
         1742366386000
        ],
        [
         "dbfs:/FileStore/tables/student-3.csv",
         "student-3.csv",
         74,
         1742373717000
        ],
        [
         "dbfs:/FileStore/tables/student.csv",
         "student.csv",
         74,
         1742365861000
        ],
        [
         "dbfs:/FileStore/tables/student_csv.xlsx",
         "student_csv.xlsx",
         8518,
         1742365410000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(dbutils.fs.ls(\"/FileStore/tables/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "491039f8-4ab5-4b66-aaa6-fbb41e8de2d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"StreamingDemo\").getOrCreate()\n",
    "\n",
    "# Define the schema explicitly (added a timestamp column for watermarking)\n",
    "schema = StructType([\n",
    "    StructField(\"EMPLOYEE_ID\", StringType(), True),\n",
    "    StructField(\"FIRST_NAME\", StringType(), True),\n",
    "    StructField(\"SALARY\", IntegerType(), True),\n",
    "    StructField(\"EVENT_TIMESTAMP\", TimestampType(), True)  # Add a timestamp column\n",
    "])\n",
    "\n",
    "# Read streaming data from a folder\n",
    "df = spark.readStream.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"/FileStore/tables/\")\n",
    "\n",
    "# Apply watermarking to manage late data (assuming the 'EVENT_TIMESTAMP' is the event time)\n",
    "df_with_watermark = df.withWatermark(\"EVENT_TIMESTAMP\", \"1 hour\")  # Allow late data up to 1 hour\n",
    "\n",
    "# Apply a transformation (you can adjust this as needed)\n",
    "df_transformed = df_with_watermark.select(\"EMPLOYEE_ID\", \"FIRST_NAME\", \"SALARY\", \"EVENT_TIMESTAMP\")\n",
    "\n",
    "# Write the output to console with a trigger interval of 5 seconds\n",
    "query = df_transformed.writeStream.format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "advdatabricks_day2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
